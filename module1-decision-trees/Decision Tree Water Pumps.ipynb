{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47520, 41), (11880, 41))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in data\n",
    "local = '../data/tanzania/'\n",
    "\n",
    "train = pd.merge(pd.read_csv(local+'train_features.csv'),\n",
    "                 pd.read_csv(local+'train_labels.csv'))\n",
    "test = pd.read_csv(local+'test_features.csv')\n",
    "sample_submission = pd.read_csv(local+'sample_submission.csv')\n",
    "#split train data into train and validation\n",
    "train, val = train_test_split(train, train_size=0.8, test_size = 0.2,\n",
    "                              stratify = train['status_group'], random_state=42)\n",
    "train.shape, val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Wrangle(X):\n",
    "    #This function will help us handle strange or missing values\n",
    "    X = X.copy()\n",
    "    \n",
    "    #The latitude column has a very values extremely close to zero, we're going to fix that\n",
    "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
    "    \n",
    "    #When we have 0's and know we shouldn't, it's best to replace them with nans\n",
    "    #In this case, we'll use the column mean to replace them\n",
    "    cols_with_zeros = ['construction_year', 'longitude', 'latitude']\n",
    "    for col in cols_with_zeros:\n",
    "        X[col] = X[col].replace(0, np.nan)\n",
    "        X[col] = X[col].fillna(X[col].mean())\n",
    "    \n",
    "    #Convert date recorded to datetime format\n",
    "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format = True)\n",
    "    \n",
    "    #We have some columns that are duplicates, so we'll drop one of them here\n",
    "    X = X.drop(columns = 'quantity_group')\n",
    "    \n",
    "    #Now we replace missing categorical values with the MISSING category\n",
    "    categoricals = X.select_dtypes(exclude = 'number').columns\n",
    "    for col in categoricals:\n",
    "        X[col] = X[col].fillna('MISSING')\n",
    "        \n",
    "    return X\n",
    "\n",
    "train = Wrangle(train)\n",
    "val = Wrangle(val)\n",
    "test = Wrangle(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recorded_by                  1\n",
       "public_meeting               3\n",
       "source_class                 3\n",
       "permit                       3\n",
       "quantity                     5\n",
       "management_group             5\n",
       "quality_group                6\n",
       "waterpoint_type_group        6\n",
       "payment_type                 7\n",
       "payment                      7\n",
       "source_type                  7\n",
       "waterpoint_type              7\n",
       "extraction_type_class        7\n",
       "water_quality                8\n",
       "basin                        9\n",
       "source                      10\n",
       "management                  12\n",
       "scheme_management           13\n",
       "extraction_type_group       13\n",
       "extraction_type             18\n",
       "region                      21\n",
       "lga                        124\n",
       "date_recorded              349\n",
       "funder                    1717\n",
       "installer                 1930\n",
       "ward                      2082\n",
       "scheme_name               2564\n",
       "subvillage               17232\n",
       "wpt_name                 30661\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separate training set into features and target\n",
    "target = 'status_group'\n",
    "\n",
    "train_features = train.drop(columns =[target,'id'] )\n",
    "#List of the numeric features\n",
    "numeric_features = train_features.select_dtypes(include = 'number').columns.tolist()\n",
    "#Examine cardinality of categorical features to discover encoding candidates\n",
    "cardinality = train_features.select_dtypes(exclude = 'number').nunique()\n",
    "cardinality.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a list of all categories with a cardinality of 21 or less\n",
    "categorical_features = cardinality[cardinality<=21].index.tolist()\n",
    "\n",
    "#create our feature list\n",
    "features = categorical_features + numeric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arrange into X_features and y_target matrices\n",
    "X_train = train[features]\n",
    "X_val = val[features]\n",
    "X_test = test[features]\n",
    "\n",
    "y_train = train[target]\n",
    "y_val = val[target]\n",
    "\n",
    "#perform encoding and scaling of features\n",
    "encoder = ce.OneHotEncoder(use_cat_names = True)\n",
    "X_train_encoded = encoder.fit_transform(X_train)\n",
    "X_val_encoded = encoder.transform(X_val)\n",
    "X_test_encoded = encoder.transform(X_test)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
    "X_val_scaled = scaler.transform(X_val_encoded)\n",
    "X_test_scaled = scaler.transform(X_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy Score: 0.7586700336700337\n"
     ]
    }
   ],
   "source": [
    "#Fit to decision tree\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Score on validation set\n",
    "print(f'Validation Accuracy Score: {dt.score(X_val_scaled, y_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pred = dt.predict(X_test_scaled)\n",
    "\n",
    "submission = sample_submission.copy()\n",
    "submission['status_group'] = dt_pred\n",
    "submission.to_csv('Submission-01.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
